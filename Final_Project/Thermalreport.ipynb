{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"18tNe80D1ZwtqpxxEQMtjHnZkgG6RS3RI","timestamp":1744159351309}],"machine_shape":"hm","gpuType":"A100","collapsed_sections":["HcDOfVGfeno7","gtXz6eNLb1nS"],"authorship_tag":"ABX9TyOdlH1G3Ea2CuslvqHWQw8X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Thermal"],"metadata":{"id":"80qHRTJvbsIY"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745530898613,"user_tz":240,"elapsed":20193,"user":{"displayName":"Laksita Prasanna","userId":"18398610799750086286"}},"outputId":"874e8414-f020-43b6-954e-f705cc5e2ced","id":"bboWTHW1b1my"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import zipfile\n","import os\n","zip_file = \"/content/drive/MyDrive/archive.zip\"\n","extract_dir = \"final_data\"\n","if not os.path.exists(extract_dir) or not os.listdir(extract_dir):\n","  os.makedirs(extract_dir, exist_ok=True)\n","  with zipfile.ZipFile(zip_file, 'r') as ref:\n","    ref.extractall(extract_dir)\n","  print('Extraction complete')\n","else:\n","    print(\"Extraction skipped/already exists.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745531045911,"user_tz":240,"elapsed":141881,"user":{"displayName":"Laksita Prasanna","userId":"18398610799750086286"}},"outputId":"18ea6fcd-34a3-43cc-d8d8-f5e253e3380f","id":"_LZcuCpKb1nR"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Extraction complete\n"]}]},{"cell_type":"markdown","source":["# CNN"],"metadata":{"id":"HcDOfVGfeno7"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","from PIL import Image\n","import tensorflow as tf\n","from collections import defaultdict\n","\n","# Load predictions and labels\n","true_labels = np.load(\"CNNTrueLabelsThermal.npy\")\n","cnn_preds = np.load(\"CNNPredLabelsThermal.npy\")\n","patches_df = pd.read_csv(\"/content/patches_thermal_val_info.csv\")\n","\n","# Class Labels\n","class_names = ['bike', 'bus', 'car', 'person', 'sign', 'motor', 'light', 'truck']\n","\n","# Load validation dataset (to get .file_paths)\n","classes = {cls: i for i, cls in enumerate(class_names)}\n","val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n","    \"/content/final_data/Val_IR/val_thermal_patches\",\n","    labels='inferred',\n","    label_mode='int',\n","    class_names=list(classes.keys()),\n","    image_size=(64, 64),\n","    batch_size=512,\n","    shuffle=False,\n",")\n","\n","# Extract list of file paths\n","val_file_paths = list(val_dataset.file_paths)\n","\n","# Find misclassified samples\n","misclassified_indices = np.where(true_labels != cnn_preds)[0]\n","\n","# Create a mapping from patch filename to index in val_file_paths\n","filename_to_val_index = {os.path.basename(path): i for i, path in enumerate(val_file_paths)}\n","\n","# Filter misclassified_indices to only include those present in val_file_paths\n","valid_misclassified_indices = [\n","    idx\n","    for idx in misclassified_indices\n","    if os.path.basename(val_file_paths[idx % len(val_file_paths)]) in filename_to_val_index  # Using modulo to handle potential index overflow\n","]\n","\n","# Select 2 misclassified samples from each class\n","grouped_misclassified = defaultdict(list)\n","for idx in valid_misclassified_indices:\n","    true_class = true_labels[idx]\n","    if len(grouped_misclassified[true_class]) < 2:\n","        patch_filename = os.path.basename(val_file_paths[idx % len(val_file_paths)])  # match by filename\n","        if patch_filename in filename_to_val_index:\n","            val_idx = filename_to_val_index[patch_filename]\n","            grouped_misclassified[true_class].append(val_idx)\n","\n","# Visualize\n","for class_id, indices in grouped_misclassified.items():\n","    for idx in indices:\n","        patch_path = val_file_paths[idx]\n","        patch_filename = os.path.basename(patch_path)\n","\n","        # Get original image + bbox\n","        row = patches_df[patches_df['patch_filename'] == patch_filename].iloc[0]\n","        original_img_path = os.path.join(\n","            '/content/final_data/Val_IR/',\n","            row['original_filename']\n","        )\n","        bbox = eval(str(row['bbox']))\n","\n","        # Load images\n","        original_img = Image.open(original_img_path)\n","        patch_img = Image.open(patch_path)\n","\n","        # Plot side-by-side\n","        fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n","\n","        # Original image with bbox\n","        ax[0].imshow(original_img)\n","        ax[0].set_title(f\"True: {class_names[true_labels[idx]]}, Pred: {class_names[cnn_preds[idx]]}\")\n","        rect = patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], linewidth=2, edgecolor='red', facecolor='none')\n","        ax[0].add_patch(rect)\n","\n","        # Cropped patch\n","        ax[1].imshow(patch_img)\n","        ax[1].set_title(\"Cropped Patch\")\n","\n","        plt.tight_layout()\n","        plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1_EF58QzlwvraCf803nLkoQsFARuivbxt"},"executionInfo":{"status":"ok","timestamp":1744170254023,"user_tz":240,"elapsed":7832,"user":{"displayName":"Laksita Prasanna","userId":"18398610799750086286"}},"outputId":"0f320312-9506-4163-f251-6145e2568603","id":"jmdCYWqdb1nS"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["# VGG\n","\n"],"metadata":{"id":"gtXz6eNLb1nS"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","from PIL import Image\n","import tensorflow as tf\n","from collections import defaultdict\n","\n","# Load predictions and labels\n","vgg_true_labels = np.load(\"VGGTrueLabelsThermal.npy\")\n","vgg_preds = np.load(\"VGGPredLabelsThermal.npy\")\n","patches_df = pd.read_csv(\"/content/patches_thermal_val_info.csv\")\n","\n","# Class Labels\n","class_names = ['bike', 'bus', 'car', 'person', 'sign', 'motor', 'light', 'truck']\n","\n","# Load validation dataset (to get .file_paths)\n","classes = {cls: i for i, cls in enumerate(class_names)}\n","val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n","    \"/content/final_data/Val_IR/val_thermal_patches\",\n","    labels='inferred',\n","    label_mode='int',\n","    class_names=list(classes.keys()),\n","    image_size=(64, 64),\n","    batch_size=512,\n","    shuffle=False,\n",")\n","\n","# Extract list of file paths\n","val_file_paths = list(val_dataset.file_paths)\n","\n","# Find misclassified samples\n","misclassified_indices_vgg = np.where(vgg_true_labels != vgg_preds)[0]\n","\n","# Select 2 misclassified samples from each class\n","grouped_vgg_misclassified = defaultdict(list)\n","for idx in misclassified_indices_vgg:\n","    true_class = vgg_true_labels[idx]\n","    if len(grouped_vgg_misclassified[true_class]) < 2:\n","        grouped_vgg_misclassified[true_class].append(idx)\n","\n","# Visualize\n","for class_id, indices in grouped_vgg_misclassified.items():\n","    for idx in indices:\n","        patch_path = val_file_paths[idx]\n","        patch_filename = os.path.basename(patch_path)\n","\n","        # Get original image + bbox\n","        if patch_filename in patches_df['patch_filename'].values:\n","          row = patches_df[patches_df['patch_filename'] == patch_filename].iloc[0]\n","          original_img_path = os.path.join(\n","              '/content/final_data/Val_IR/',\n","              row['original_filename']\n","          )\n","          bbox = eval(str(row['bbox']))\n","\n","          # Load images\n","          original_img = Image.open(original_img_path)\n","          patch_img = Image.open(patch_path)\n","\n","          # Plot side-by-side\n","          fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n","\n","          # Original image with bbox\n","          ax[0].imshow(original_img)\n","          ax[0].set_title(f\"True: {class_names[vgg_true_labels[idx]]}, Pred: {class_names[vgg_preds[idx]]}\")\n","          rect = patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], linewidth=2, edgecolor='red', facecolor='none')\n","          ax[0].add_patch(rect)\n","\n","          # Cropped patch\n","          ax[1].imshow(patch_img)\n","          ax[1].set_title(\"Cropped Patch\")\n","\n","          plt.tight_layout()\n","          plt.show()\n","        else:\n","            print(f\"Warning: patch_filename '{patch_filename}' not found in patches_df. Skipping visualization.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"16R-YmtDsDBcvYqWWRF18GfE-EGR4H5ud"},"executionInfo":{"status":"error","timestamp":1744169180996,"user_tz":240,"elapsed":3214,"user":{"displayName":"Laksita Prasanna","userId":"18398610799750086286"}},"outputId":"71ecd30c-1e1f-49e5-c555-c4d6ad2e1502","id":"Tm9P_fOeb1nT"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["# Autoencoder"],"metadata":{"id":"VH7tkx2ouLSc"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","from PIL import Image\n","import tensorflow as tf\n","from collections import defaultdict\n","\n","# Load predictions and labels\n","ae_true_labels = np.load(\"AETrueLabelsThermal.npy\")\n","ae_preds = np.load(\"AEPredLabelsThermal.npy\")\n","patches_df = pd.read_csv(\"/content/patches_thermal_val_info.csv\")\n","\n","# Class Labels\n","class_names = ['bike', 'bus', 'car', 'person', 'sign', 'motor', 'light', 'truck']\n","\n","# Load validation dataset (to get .file_paths)\n","classes = {cls: i for i, cls in enumerate(class_names)}\n","val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n","    \"/content/final_data/Val_IR/val_thermal_patches\",\n","    labels='inferred',\n","    label_mode='int',\n","    class_names=list(classes.keys()),\n","    image_size=(64, 64),\n","    batch_size=512,\n","    shuffle=False,\n",")\n","\n","# Extract list of file paths\n","val_file_paths = list(val_dataset.file_paths)\n","\n","# Find misclassified samples\n","misclassified_indices_ae = np.where(ae_true_labels != ae_preds)[0]\n","\n","# Select 2 misclassified samples from each class\n","grouped_ae_misclassified = defaultdict(list)\n","for idx in misclassified_indices_ae:\n","  true_class = ae_true_labels[idx]\n","  if len(grouped_ae_misclassified[true_class]) < 2:\n","      grouped_ae_misclassified[true_class].append(idx)\n","\n","# Visualize\n","for class_id, indices in grouped_ae_misclassified.items():\n","  for idx in indices:\n","    if idx < len(val_file_paths):\n","      patch_path = val_file_paths[idx]\n","      patch_filename = os.path.basename(patch_path)\n","\n","      # Get original image + bbox\n","      if patch_filename in patches_df['patch_filename'].values:\n","        row = patches_df[patches_df['patch_filename'] == patch_filename].iloc[0]\n","        original_img_path = os.path.join(\n","            '/content/final_data/Val_IR/',\n","            row['original_filename']\n","        )\n","        bbox = eval(str(row['bbox']))\n","\n","        # Load images\n","        original_img = Image.open(original_img_path)\n","        patch_img = Image.open(patch_path)\n","\n","        # Plot side-by-side\n","        fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n","\n","        # Original image with bbox\n","        ax[0].imshow(original_img)\n","        ax[0].set_title(f\"True: {class_names[ae_true_labels[idx]]}, Pred: {class_names[ae_preds[idx]]}\")\n","        rect = patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], linewidth=2, edgecolor='red', facecolor='none')\n","        ax[0].add_patch(rect)\n","\n","        # Cropped patch\n","        ax[1].imshow(patch_img)\n","        ax[1].set_title(\"Cropped Patch\")\n","\n","        plt.tight_layout()\n","        plt.show()\n","      else:\n","          print(f\"Warning: patch_filename '{patch_filename}' not found in patches_df. Skipping visualization.\")\n","    else:\n","      print(f\"Warning: Index {idx} is out of bounds for val_file_paths. Skipping visualization.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0,"output_embedded_package_id":"1beeTKNODsxIRpW543ldLXYeAjZwgyrNL"},"id":"ekU4F1aMecpz","executionInfo":{"status":"ok","timestamp":1745531453085,"user_tz":240,"elapsed":3286,"user":{"displayName":"Laksita Prasanna","userId":"18398610799750086286"}},"outputId":"52493517-dd41-404b-a4ee-2663cac42abf"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}